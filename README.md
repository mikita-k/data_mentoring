# Installation guide:

used hadoop https://github.com/steveloughran/winutils/blob/master/hadoop-3.0.0/bin/winutils.exe

used spark  https://www.apache.org/dyn/closer.lua/spark/spark-3.2.2/spark-3.2.2-bin-hadoop3.2.tgz

1. add interpretator (python 3.9.0)
2. python -m pip install --upgrade pip
3. pip install -r requirements.txt

---
Homework 01:
1. Run main logic:
   2. run hw_spark_basic_homework/src/main/execute_me.py
2. Check results:
   1. run hw_spark_basic_homework/src/main/output/check_result.py
- NB! To choose local and remote data switch variable get_local_data: 
- hw_spark_basic_homework/src/main/utils/dataframe.py:6

---
